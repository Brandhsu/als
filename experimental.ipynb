{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from fcn import *\n",
    "from data import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Dataframe format\n",
    "\n",
    "* One dataframe for saving latent features with columns\n",
    "\n",
    "PATIENT ID | CLASS | VALIDATION LATENT FEAUTES\n",
    "* One dataframe for saving input feature vectors and names\n",
    "\n",
    "PATIENT ID | CLASS | VALIDATION FEATURES\n",
    "\n",
    "**All features will be generated using leave-one-out cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2021-05-13 02:31:28 ] CUDA_VISIBLE_DEVICES automatically set to: 1           \n"
     ]
    }
   ],
   "source": [
    "#--- Autoselect GPU\n",
    "from jarvis.utils.general import gpus\n",
    "gpus.autoselect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out why chi2 is so high for als no als\n",
    "# TODO: get and reproduce baselines...\n",
    "# TODO: add specialized class splitting\n",
    "# DEBUG: why is mutual info lower in new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(norm=False, feat_select=False):\n",
    "    return load_data(norm=norm, feat_select=feat_select)\n",
    "    \n",
    "def load_dataset(path='./DESeq2_reduced.pkl'):\n",
    "    dataset = load(path)\n",
    "    return SimpleNamespace(**dataset)\n",
    "\n",
    "def normalize(X):\n",
    "    X = X - np.min(X, axis=0, keepdims=True)\n",
    "    X = X / np.max(X, axis=0, keepdims=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add feature selection visualizer to compare between mutual information and chi^2.\n",
    "\n",
    "# The mutual information has a lot more unique feature values, however maybe this variation causes too much noise and chi^2 is better especially because the dataset is small\n",
    "\n",
    "# The features are very sparse lot's of clustering at 0 and 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Loss vs. Multi-Loss\n",
    "\n",
    "### Datasets\n",
    "1. DESeq2_reduced.pkl is a dataset with 5 losses with features corresponding to the top 1% of mutual information feature selection for the ctrl vs. case task\n",
    "2. DESeq2_all_reduced.pkl is a dataset with 5 losses with features corresponding to the top 1% of mutual information feature selection for all tasks\n",
    "3. DESeq2_all_reduced_tiny.pkl is a dataset with 5 losses with features corresponding to the top .02% of mutual information feature selection for all tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>CtrlVsCase_Classifier</th>\n",
       "      <th>DDX11L1</th>\n",
       "      <th>WASH7P</th>\n",
       "      <th>MIR6859.1</th>\n",
       "      <th>MIR1302.2HG</th>\n",
       "      <th>FAM138A</th>\n",
       "      <th>OR4G11P</th>\n",
       "      <th>OR4F5</th>\n",
       "      <th>AL627309.1</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000278033</th>\n",
       "      <th>U1.4</th>\n",
       "      <th>U1.5</th>\n",
       "      <th>AC213203.2</th>\n",
       "      <th>AC213203.1</th>\n",
       "      <th>ENSG00000278858</th>\n",
       "      <th>Bulbar_Classifier</th>\n",
       "      <th>Median_Classifier</th>\n",
       "      <th>Limb_Classifier</th>\n",
       "      <th>High_Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEUAB000NKC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>188.401759</td>\n",
       "      <td>32.563267</td>\n",
       "      <td>1.162974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.814869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.200880</td>\n",
       "      <td>2.325948</td>\n",
       "      <td>5.814869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEUAE993EPR</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>233.423189</td>\n",
       "      <td>27.412688</td>\n",
       "      <td>1.661375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.984125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.888875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEUAF553MJ3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>199.081434</td>\n",
       "      <td>41.519657</td>\n",
       "      <td>3.193820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.969099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.488756</td>\n",
       "      <td>3.193820</td>\n",
       "      <td>1.064607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEUAG603XLK</td>\n",
       "      <td>1</td>\n",
       "      <td>2.152546</td>\n",
       "      <td>122.695105</td>\n",
       "      <td>34.440731</td>\n",
       "      <td>2.152546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.152546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.610183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.271280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.305091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEUAM655HF7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.017494</td>\n",
       "      <td>19.679458</td>\n",
       "      <td>1.229966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.919865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.578442</td>\n",
       "      <td>1.229966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NEUUV825HYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>257.219991</td>\n",
       "      <td>55.316127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.680322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.572579</td>\n",
       "      <td>1.382903</td>\n",
       "      <td>1.382903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NEUVZ050YX7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.129306</td>\n",
       "      <td>34.032327</td>\n",
       "      <td>2.520913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.260457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.083652</td>\n",
       "      <td>...</td>\n",
       "      <td>1.260457</td>\n",
       "      <td>60.501914</td>\n",
       "      <td>1.260457</td>\n",
       "      <td>2.520913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NEUWT164JRQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>104.411115</td>\n",
       "      <td>26.102779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.601342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.112361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NEUYM205MRL</td>\n",
       "      <td>0</td>\n",
       "      <td>1.032984</td>\n",
       "      <td>43.385342</td>\n",
       "      <td>12.395812</td>\n",
       "      <td>2.065969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.362828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.253405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NEUZL045YD3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.897778</td>\n",
       "      <td>14.475932</td>\n",
       "      <td>0.804218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.888588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.406704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.216874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 53865 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Participant_ID  CtrlVsCase_Classifier   DDX11L1      WASH7P  MIR6859.1  \\\n",
       "0      NEUAB000NKC                      1  0.000000  188.401759  32.563267   \n",
       "1      NEUAE993EPR                      1  0.000000  233.423189  27.412688   \n",
       "2      NEUAF553MJ3                      1  0.000000  199.081434  41.519657   \n",
       "3      NEUAG603XLK                      1  2.152546  122.695105  34.440731   \n",
       "4      NEUAM655HF7                      1  0.000000   91.017494  19.679458   \n",
       "..             ...                    ...       ...         ...        ...   \n",
       "158    NEUUV825HYF                      0  0.000000  257.219991  55.316127   \n",
       "159    NEUVZ050YX7                      0  0.000000  136.129306  34.032327   \n",
       "160    NEUWT164JRQ                      0  0.000000  104.411115  26.102779   \n",
       "161    NEUYM205MRL                      0  1.032984   43.385342  12.395812   \n",
       "162    NEUZL045YD3                      0  0.000000   94.897778  14.475932   \n",
       "\n",
       "     MIR1302.2HG  FAM138A   OR4G11P  OR4F5  AL627309.1  ...  ENSG00000278033  \\\n",
       "0       1.162974      0.0  0.000000    0.0    5.814869  ...         0.000000   \n",
       "1       1.661375      0.0  0.000000    0.0    4.984125  ...         0.000000   \n",
       "2       3.193820      0.0  0.000000    0.0   15.969099  ...         0.000000   \n",
       "3       2.152546      0.0  2.152546    0.0    8.610183  ...         0.000000   \n",
       "4       1.229966      0.0  0.000000    0.0    4.919865  ...         0.000000   \n",
       "..           ...      ...       ...    ...         ...  ...              ...   \n",
       "158     0.000000      0.0  0.000000    0.0    9.680322  ...         0.000000   \n",
       "159     2.520913      0.0  1.260457    0.0   10.083652  ...         1.260457   \n",
       "160     0.000000      0.0  0.000000    0.0   12.601342  ...         0.000000   \n",
       "161     2.065969      0.0  0.000000    0.0   11.362828  ...         0.000000   \n",
       "162     0.804218      0.0  0.000000    0.0   16.888588  ...         0.000000   \n",
       "\n",
       "           U1.4      U1.5  AC213203.2  AC213203.1  ENSG00000278858  \\\n",
       "0     94.200880  2.325948    5.814869         0.0              0.0   \n",
       "1     34.888875  0.000000    0.830688         0.0              0.0   \n",
       "2     57.488756  3.193820    1.064607         0.0              0.0   \n",
       "3     60.271280  0.000000    4.305091         0.0              0.0   \n",
       "4     56.578442  1.229966    0.000000         0.0              0.0   \n",
       "..          ...       ...         ...         ...              ...   \n",
       "158   34.572579  1.382903    1.382903         0.0              0.0   \n",
       "159   60.501914  1.260457    2.520913         0.0              0.0   \n",
       "160  116.112361  0.000000    0.900096         0.0              0.0   \n",
       "161   39.253405  0.000000    0.000000         0.0              0.0   \n",
       "162   39.406704  0.000000    3.216874         0.0              0.0   \n",
       "\n",
       "     Bulbar_Classifier  Median_Classifier  Limb_Classifier  High_Classifier  \n",
       "0                  1.0                0.0              0.0              1.0  \n",
       "1                  0.0                0.0              0.0              1.0  \n",
       "2                  0.0                0.0              1.0              0.0  \n",
       "3                  1.0                0.0              0.0              1.0  \n",
       "4                  1.0                1.0              0.0              0.0  \n",
       "..                 ...                ...              ...              ...  \n",
       "158                0.0                0.0              0.0              0.0  \n",
       "159                0.0                0.0              0.0              0.0  \n",
       "160                0.0                0.0              0.0              0.0  \n",
       "161                0.0                0.0              0.0              0.0  \n",
       "162                0.0                0.0              0.0              0.0  \n",
       "\n",
       "[163 rows x 53865 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Show data for (1.)\n",
    "dataset = load_dataset('pkls/group/DESeq2_reduced.pkl')\n",
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "CtrlVsCase_Classifier\n",
      "--- Training Results\n",
      "acc     score: 1.0\n",
      "roc_auc score: 1.0\n",
      "prc_auc score: 1.0\n",
      "--- Validation Results\n",
      "acc     score: 0.9183673469387755\n",
      "roc_auc score: 0.9333333333333333\n",
      "prc_auc score: 0.9844804803861014\n"
     ]
    }
   ],
   "source": [
    "# --- Train single loss\n",
    "dataset = load_dataset('pkls/group/DESeq2_reduced.pkl')\n",
    "dataset.start = 0\n",
    "dataset.losses = dataset.losses[0:2]\n",
    "history, model = learn(dataset, lr=3e-3, batch_size=64, epochs=100, drop=0.5, n_folds=1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CtrlVsCase_Classifier\n",
      "acc     score: 0.7719298245614035\n",
      "roc_auc score: 0.9605734767025089\n",
      "prc_auc score: 0.9913362026559122\n",
      "acc     score: 0.8367346938775511\n",
      "roc_auc score: 0.9388888888888889\n",
      "prc_auc score: 0.9862931628108756\n",
      "Bulbar_Classifier\n",
      "acc     score: 0.7105263157894737\n",
      "roc_auc score: 0.889196675900277\n",
      "prc_auc score: 0.8949488614974064\n",
      "acc     score: 0.5714285714285714\n",
      "roc_auc score: 0.575\n",
      "prc_auc score: 0.5644357228929467\n",
      "Median_Classifier\n",
      "acc     score: 0.35964912280701755\n",
      "roc_auc score: 0.19588029537504856\n",
      "prc_auc score: 0.17064489258162324\n",
      "acc     score: 0.5918367346938775\n",
      "roc_auc score: 0.5408163265306123\n",
      "prc_auc score: 0.3396739541971839\n",
      "Limb_Classifier\n",
      "acc     score: 0.956140350877193\n",
      "roc_auc score: 0.9841269841269841\n",
      "prc_auc score: 0.9473154860634914\n",
      "acc     score: 0.7346938775510204\n",
      "roc_auc score: 0.4083333333333333\n",
      "prc_auc score: 0.14372382866464883\n",
      "High_Classifier\n",
      "acc     score: 0.45614035087719296\n",
      "roc_auc score: 0.25396825396825395\n",
      "prc_auc score: 0.17832625882566275\n",
      "acc     score: 0.673469387755102\n",
      "roc_auc score: 0.722972972972973\n",
      "prc_auc score: 0.36534576579104816\n"
     ]
    }
   ],
   "source": [
    "# --- Train multi-loss\n",
    "dataset = load_dataset('pkls/group/DESeq2_reduced.pkl')\n",
    "dataset.start = 0\n",
    "history, model = learn(dataset, lr=3e-3, batch_size=64, epochs=100, drop=0.5, n_folds=1, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**\n",
    "\n",
    "From these results it is obvious that a feed-forward neural network trained with multi-loss struggles to converge. This may be due to the dataset size and also the fact that mutual information feature selection is being done on only a single task instead of all. \n",
    "\n",
    "Thus our next step is to try feature selection on all tasks, and concatenate the resulting features together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CtrlVsCase_Classifier\n",
      "acc     score: 0.7017543859649122\n",
      "roc_auc score: 1.0\n",
      "prc_auc score: 1.0\n",
      "acc     score: 0.6938775510204082\n",
      "roc_auc score: 0.7402777777777778\n",
      "prc_auc score: 0.9054048121398618\n",
      "Bulbar_Classifier\n",
      "acc     score: 0.7105263157894737\n",
      "roc_auc score: 0.9444444444444444\n",
      "prc_auc score: 0.950928052911302\n",
      "acc     score: 0.5102040816326531\n",
      "roc_auc score: 0.6200000000000001\n",
      "prc_auc score: 0.6593996602363652\n",
      "Median_Classifier\n",
      "acc     score: 0.40350877192982454\n",
      "roc_auc score: 0.09483093664982511\n",
      "prc_auc score: 0.15512670942412699\n",
      "acc     score: 0.6122448979591837\n",
      "roc_auc score: 0.47244897959183674\n",
      "prc_auc score: 0.2828797692402075\n",
      "Limb_Classifier\n",
      "acc     score: 0.8157894736842105\n",
      "roc_auc score: 0.9654377880184332\n",
      "prc_auc score: 0.8348609692107325\n",
      "acc     score: 0.5918367346938775\n",
      "roc_auc score: 0.5472222222222223\n",
      "prc_auc score: 0.17918397000040004\n",
      "High_Classifier\n",
      "acc     score: 0.35964912280701755\n",
      "roc_auc score: 0.09722222222222221\n",
      "prc_auc score: 0.15446956519788688\n",
      "acc     score: 0.6326530612244898\n",
      "roc_auc score: 0.5518018018018017\n",
      "prc_auc score: 0.32481709678651766\n"
     ]
    }
   ],
   "source": [
    "# --- Train multi-loss with feature selection on all losses (p1)\n",
    "dataset = load_dataset('pkls/group/DESeq2_all_reduced.pkl')\n",
    "dataset.start = 0\n",
    "history, model = learn(dataset, lr=3e-3, batch_size=64, epochs=100, drop=0.5, n_folds=1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CtrlVsCase_Classifier\n",
      "acc     score: 0.7719298245614035\n",
      "roc_auc score: 0.8125960061443932\n",
      "prc_auc score: 0.9594234714480145\n",
      "acc     score: 0.7142857142857143\n",
      "roc_auc score: 0.6\n",
      "prc_auc score: 0.8638393190029524\n",
      "Bulbar_Classifier\n",
      "acc     score: 0.6929824561403509\n",
      "roc_auc score: 0.8165589412126808\n",
      "prc_auc score: 0.7893395029549168\n",
      "acc     score: 0.5306122448979592\n",
      "roc_auc score: 0.6033333333333334\n",
      "prc_auc score: 0.6712757341590616\n",
      "Median_Classifier\n",
      "acc     score: 0.35964912280701755\n",
      "roc_auc score: 0.22425184609405363\n",
      "prc_auc score: 0.1746419711595185\n",
      "acc     score: 0.5306122448979592\n",
      "roc_auc score: 0.5122448979591837\n",
      "prc_auc score: 0.3034588863170158\n",
      "Limb_Classifier\n",
      "acc     score: 0.9210526315789473\n",
      "roc_auc score: 0.9810547875064004\n",
      "prc_auc score: 0.9312930463622622\n",
      "acc     score: 0.7142857142857143\n",
      "roc_auc score: 0.5222222222222223\n",
      "prc_auc score: 0.1865005186822392\n",
      "High_Classifier\n",
      "acc     score: 0.35964912280701755\n",
      "roc_auc score: 0.1615079365079365\n",
      "prc_auc score: 0.15938136308281556\n",
      "acc     score: 0.42857142857142855\n",
      "roc_auc score: 0.6418918918918919\n",
      "prc_auc score: 0.32890556283221273\n"
     ]
    }
   ],
   "source": [
    "# --- Train multi-loss with feature selection on all losses (p2)\n",
    "dataset = load_dataset('pkls/group/DESeq2_all_reduced_tiny.pkl')\n",
    "dataset.start = 0\n",
    "history, model = learn(dataset, lr=3e-3, batch_size=64, epochs=100, drop=0.5, n_folds=1, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**\n",
    "\n",
    "From these results it is shown that training a neural network on muliple tasks for the given dataset is challenging even when considering feature selection on mulitple targets. The difference between p1 and p2 is that p1 contains ~5x more features than p2. As shown from the results between p1 and p2, performance remained roughly similar even when decreasing the amount of features.\n",
    "\n",
    "Moreover, the result is not even close to the performance attainable when training on a single loss.\n",
    "\n",
    "We hypothesize given the nature of the current dataset that multi-loss training is not a feasible approach. Furthermore, we believe that each task has a different difficulty level which makes it even harder for the network to learn. For instance it is possible that the neural network overfits for certain tasks while underfits for another task.\n",
    "\n",
    "Empirically we find that: \n",
    "1. Median low vs High requires the least complex features to separate the data\n",
    "2. Bulbar vs Limb requires complexity between 1. and 3. to separate the data\n",
    "3. Ctrl vs Case requires the most complex features to separate the data\n",
    "\n",
    "Due to these difficulties, we opt for a single loss approach as it yields significantly higher performance.\n",
    "\n",
    "The rest of our approach relies on training a single network only on specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Loss Datasets\n",
    "\n",
    "Examples to load different datasets are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "SiteOnset_Class\n",
      "acc     score: 1.0\n",
      "roc_auc score: 1.0\n",
      "prc_auc score: 1.0\n",
      "acc     score: 0.8823529411764706\n",
      "roc_auc score: 0.9466666666666667\n",
      "prc_auc score: 0.9796068068891869\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "SiteOnset_Class\n",
      "acc     score: 1.0\n",
      "roc_auc score: 1.0\n",
      "prc_auc score: 1.0\n",
      "acc     score: 0.9411764705882353\n",
      "roc_auc score: 1.0\n",
      "prc_auc score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# --- Bulbar vs. Limb mutual information feature selection\n",
    "dataset = load_dataset('pkls/individual/DESeq2_bl_mi.pkl')\n",
    "history, model = learn(dataset, lr=3e-3, batch_size=64, epochs=100, drop=0.5, n_folds=1, verbose=False)\n",
    "\n",
    "# --- Bulbar vs. Limb chi^2 feature selection\n",
    "dataset = load_dataset('pkls/individual/DESeq2_bl_chi.pkl')\n",
    "history, model = learn(dataset, lr=3e-3, batch_size=64, epochs=100, drop=0.5, n_folds=1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "CtrlVsCase_Classifier\n",
      "--- Training Results\n",
      "acc     score: 0.9912280701754386\n",
      "roc_auc score: 1.0\n",
      "prc_auc score: 1.0\n",
      "--- Validation Results\n",
      "acc     score: 0.8775510204081632\n",
      "roc_auc score: 0.9083333333333333\n",
      "prc_auc score: 0.9772878326207415\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "CtrlVsCase_Classifier\n",
      "--- Training Results\n",
      "acc     score: 1.0\n",
      "roc_auc score: 1.0\n",
      "prc_auc score: 1.0\n",
      "--- Validation Results\n",
      "acc     score: 0.8571428571428571\n",
      "roc_auc score: 0.7611111111111112\n",
      "prc_auc score: 0.844631017667826\n"
     ]
    }
   ],
   "source": [
    "# --- Ctrl vs. Case mutual information feature selection\n",
    "dataset = load_dataset('pkls/individual/DESeq2_cc_mi.pkl')\n",
    "history, model = learn(dataset, lr=3e-3, batch_size=64, epochs=100, drop=0.5, n_folds=1, verbose=False)\n",
    "\n",
    "# --- Ctrl vs. Case chi^2 feature selection\n",
    "dataset = load_dataset('pkls/individual/DESeq2_cc_chi.pkl')\n",
    "history, model = learn(dataset, lr=3e-3, batch_size=64, epochs=100, drop=0.5, n_folds=1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "ALSFRS_Class_Median\n",
      "acc     score: 1.0\n",
      "roc_auc score: 1.0\n",
      "prc_auc score: 0.9999999999999998\n",
      "acc     score: 0.5925925925925926\n",
      "roc_auc score: 0.6758241758241759\n",
      "prc_auc score: 0.7485413756901699\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "ALSFRS_Class_Median\n",
      "acc     score: 1.0\n",
      "roc_auc score: 1.0\n",
      "prc_auc score: 0.9999999999999998\n",
      "acc     score: 1.0\n",
      "roc_auc score: 1.0\n",
      "prc_auc score: 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "# --- Median low vs. High mutual information feature selection\n",
    "dataset = load_dataset('pkls/individual/DESeq2_mh_mi.pkl')\n",
    "history, model = learn(dataset, lr=3e-3, batch_size=64, epochs=100, drop=0.5, n_folds=1, verbose=False)\n",
    "\n",
    "# --- Median low vs. High chi^2 feature selection\n",
    "dataset = load_dataset('pkls/individual/DESeq2_mh_chi.pkl')\n",
    "history, model = learn(dataset, lr=3e-3, batch_size=64, epochs=100, drop=0.5, n_folds=1, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commet**\n",
    "\n",
    "From these results it is shown that the type of feature selection used had significant impacts depending on the dataset task.\n",
    "\n",
    "In summary:\n",
    "* Chi^2 gave better performance on the limb vs bulbar and median low vs high tasks\n",
    "* Mutual information gave better performance on the ctrl vs case task\n",
    "\n",
    "*However, across mutliple dataset splits, it was found that Chi^2 gave more numerically stable results, so all following experiments will use Chi^2 feature selection.*\n",
    "\n",
    "Next we will run leave-one-out cross validation on the each dataset task with the best performing feature selection.\n",
    "\n",
    "\n",
    "**Correction stratified version of leave-one-out is used fix all above comments that mention this!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation is performed to get the validation results on all possible training set configurations. \n",
    "\n",
    "During each fold, the latent representation of the neural network is saved for clustering.\n",
    "\n",
    "The following datasets and settings are used for each task.\n",
    "\n",
    "1. Ctrl vs Case:\n",
    "    1. Mutual information feature selection\n",
    "2. Bulbar vs Limb:\n",
    "    1. Chi^2 feature selection \n",
    "3. Median Low vs High\n",
    "    1. Chi^2 feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mi feature selection and data normalization = True\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Ctrl vs Case\n",
    "dataset = Dataset('./data/ctrl_vs_case.csv')\n",
    "dataset.feature_selection(norm=True, feat_select='mi', target=0, percentile=.01)\n",
    "n_fold = min(len(dataset.labels) - sum(dataset.labels), sum(dataset.labels))\n",
    "history, model = learn(dataset, lr=3e-3, batch_size=64, epochs=100, drop=0.5, n_folds=n_fold, verbose=False)\n",
    "\n",
    "# --- Save dataframe\n",
    "dataset.lf_df.to_csv('./outputs/ctrl_vs_case_lf.csv' ,index=False)\n",
    "dataset.ft_df.to_csv('./outputs/ctrl_vs_case_ft.csv' ,index=False)\n",
    "\n",
    "# Get Accuracy results\n",
    "acc = lambda x: sum(x)/len(x)\n",
    "a = []\n",
    "for h in (history):\n",
    "    a.append(acc(h.history['val_sparse_categorical_accuracy']))\n",
    "    \n",
    "acc(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Bulbar vs Limb\n",
    "dataset = Dataset('./data/bulbar_vs_limb.csv')\n",
    "dataset.feature_selection(norm=True, feat_select='chi', target=0, percentile=.01)\n",
    "n_fold = min(len(dataset.labels) - sum(dataset.labels), sum(dataset.labels))\n",
    "history, model = learn(dataset, lr=3e-3, batch_size=64, epochs=100, drop=0.5, n_folds=n_fold, verbose=False)\n",
    "\n",
    "# --- Save dataframe\n",
    "dataset.lf_df.to_csv('./outputs/bulbar_vs_limb_lf.csv', index=False)\n",
    "dataset.ft_df.to_csv('./outputs/bulbar_vs_limb_ft.csv' ,index=False)\n",
    "\n",
    "# Get Accuracy results\n",
    "acc = lambda x: sum(x)/len(x)\n",
    "a = []\n",
    "for h in (history):\n",
    "    a.append(acc(h.history['val_sparse_categorical_accuracy']))\n",
    "    \n",
    "acc(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9942063492181754"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. Median Low vs High\n",
    "dataset = Dataset('./data/median_low_vs_high.csv')\n",
    "dataset.feature_selection(norm=True, feat_select='chi', target=0, percentile=.01)\n",
    "n_fold = min(len(dataset.labels) - sum(dataset.labels), sum(dataset.labels))\n",
    "history, model = learn(dataset, lr=3e-3, batch_size=64, epochs=100, drop=0.5, n_folds=n_fold, verbose=False)\n",
    "\n",
    "# --- Save dataframe\n",
    "dataset.lf_df.to_csv('./outputs/median_low_vs_high_lf.csv', index=False)\n",
    "dataset.ft_df.to_csv('./outputs/median_low_vs_high_ft.csv', index=False)\n",
    "\n",
    "# Get Accuracy results\n",
    "acc = lambda x: sum(x)/len(x)\n",
    "a = []\n",
    "for h in (history):\n",
    "    a.append(acc(h.history['val_sparse_categorical_accuracy']))\n",
    "    \n",
    "acc(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add special task for using only specific patients\n",
    "# np.random.seed(0)\n",
    "# dataset = Dataset(['./data/ctrl_vs_case.csv', './data/bulbar_vs_limb.csv', './data/median_low_vs_high.csv'])\n",
    "# dataset.feature_selection(norm=True, feat_select='mi', target=0, percentile=.01)\n",
    "# dataset.split_data(train_size=0.7, start=0) # start only equal 1 when bulbar v lim or med v high\n",
    "\n",
    "# dataset = Dataset('./data/median_low_vs_high.csv')\n",
    "\n",
    "# # adjust_dataset, only change non_ attributes\n",
    "# dataset.feature_selection(norm=True, feat_select='chi', target=0, percentile=.01)\n",
    "# dataset.split_data(train_size=0.7, start=0) # start only equal 1 when bulbar v lim or med v high\n",
    "\n",
    "\n",
    "# PCA\n",
    "dataset = load_dataset('pkls/group/DESeq2_reduced.pkl')\n",
    "p = pca(dataset, n_components=10)\n",
    "df, l = pca_importance(dataset, p)\n",
    "# feature_importance(dataset)\n",
    "\n",
    "dataset = load_dataset('./DESeq2_reduced.pkl')\n",
    "p = pca(dataset, n_components=10)\n",
    "pca_importance(dataset, p)\n",
    "feature_importance(dataset)\n",
    "\n",
    "x = p.fit_transform(dataset.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Analyze model\n",
    "model.summary()\n",
    "\n",
    "# --- Save a model\n",
    "# save_model(model)\n",
    "# del model\n",
    "\n",
    "# --- Load a model\n",
    "# model = load_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
