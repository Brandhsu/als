{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Libraries\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Sequential, layers, losses, optimizers\n",
    "from sklearn import random_projection\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:** \n",
    "* https://link.springer.com/article/10.1007/s10044-018-0697-0\n",
    "* https://keras.io/examples/vision/grad_cam/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2021-04-27 12:44:59 ] CUDA_VISIBLE_DEVICES automatically set to: 1           \n"
     ]
    }
   ],
   "source": [
    "#--- Autoselect GPU\n",
    "from jarvis.utils.general import gpus\n",
    "gpus.autoselect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Blocks\n",
    "conv = lambda x, features, dr=1, name=None : layers.Conv1D(filters=features, kernel_size=1, strides=1, dilation_rate=dr, padding='same', name=name)(x)\n",
    "elu  = lambda x: layers.ELU()(x)\n",
    "norm = lambda x: layers.BatchNormalization()(x)\n",
    "mlp  = lambda x, features, dr=1: elu(norm((conv(x, features, dr))))\n",
    "\n",
    "# --- Model Architecture\n",
    "def encoder(x, features):\n",
    "    for f in features:\n",
    "        x = mlp(x, f)\n",
    "    return x\n",
    "\n",
    "def decoder(x, features):\n",
    "    features = features[::-1]\n",
    "    for f in features:\n",
    "        x = mlp(x, f)\n",
    "    return x\n",
    "\n",
    "def network(dataset):\n",
    "    tf.random.set_seed(0)\n",
    "    x = dataset.Input\n",
    "    input_size = x.shape[-1]\n",
    "    features = [128, 64]\n",
    "    embed_size = 32\n",
    "    outputs = {}\n",
    "    \n",
    "    x_ = encoder(x, features)\n",
    "    embedding = mlp(x_, embed_size)\n",
    "    x_ = decoder(embedding, features)\n",
    "\n",
    "    classification = conv(embedding, 2, name=dataset.l1)\n",
    "    reconstruction = conv(x_, input_size, name=dataset.l2)\n",
    "    \n",
    "    outputs[dataset.l1] = classification\n",
    "    outputs[dataset.l2] = reconstruction\n",
    "    \n",
    "    return Model(x, outputs)\n",
    "    \n",
    "# --- Model Compile\n",
    "def compile_(model, dataset, lr=1e-4):\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=lr), \n",
    "        loss={dataset.l1: losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              dataset.l2: losses.MSE}, \n",
    "        metrics={dataset.l1: 'accuracy', \n",
    "                 dataset.l2: 'mean_absolute_error'},\n",
    "        experimental_run_tf_function=False)\n",
    "\n",
    "    return model\n",
    "\n",
    "# --- Model Trainer\n",
    "def train(model, dataset):\n",
    "    outputs = {}\n",
    "    outputs[dataset.l1] = dataset.ytr\n",
    "    outputs[dataset.l2] = dataset.xtr\n",
    "    class_weights = {dataset.l1: dataset.weights}\n",
    "    \n",
    "    validation = {}\n",
    "    validation[dataset.l1] = dataset.yte\n",
    "    validation[dataset.l2] = dataset.xte\n",
    "    \n",
    "    history = model.fit(\n",
    "        x=dataset.xtr,\n",
    "        y=outputs, \n",
    "        batch_size=4, \n",
    "        epochs=80, \n",
    "        validation_data=(dataset.xte, validation), \n",
    "        validation_freq=10,\n",
    "        class_weight=class_weights,\n",
    "        verbose=0,\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(history):\n",
    "    print('train acc: {}'.format(history.history['classification_accuracy'][-1]))\n",
    "    print('train reconstruction error: {}'.format(history.history['reconstruction_mean_absolute_error'][-1]))\n",
    "\n",
    "    print('valid acc: {}'.format(history.history['val_classification_accuracy'][-1]))\n",
    "    print('valid reconstruction error: {}'.format(history.history['val_reconstruction_mean_absolute_error'][-1]))\n",
    "\n",
    "def pred_one_class_acc(y):\n",
    "    return sum(y/len(y))\n",
    "    \n",
    "def evaluate(model, data, labels):\n",
    "    # test on whole dataset\n",
    "    preds = model.predict(data)\n",
    "\n",
    "    if type(preds) == list: preds = preds[0];\n",
    "    preds = np.argmax(preds, axis=-1)\n",
    "    \n",
    "    print('Dominant class acc: {}'.format(pred_one_class_acc(labels)))\n",
    "    print('Model pred acc: {}'.format(accuracy_score(labels, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(path, mode):\n",
    "    # --- Prepare Data\n",
    "    dataset = Dataset(path, train_size=0.7)\n",
    "    \n",
    "    # --- Feature Selection\n",
    "    dataset.feature_selection(percentile=10, mode=mode)\n",
    "    \n",
    "    # --- Prepare Model\n",
    "    model = network(dataset)\n",
    "    model = compile_(model, dataset)\n",
    "    \n",
    "    # --- Train Model\n",
    "    history = train(model, dataset)\n",
    "    \n",
    "    # --- Summarize Results\n",
    "    print()\n",
    "    print('Training results from {}'.format(mode))\n",
    "    summarize(history)\n",
    "    print('Evaluating results from {}'.format(mode))\n",
    "    print('Train')\n",
    "    evaluate(model, dataset.xtr, dataset.ytr)\n",
    "    print('Test')\n",
    "    evaluate(model, dataset.xte, dataset.yte)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default not in {chi, mutual_info} so using default features\n",
      "\n",
      "Training results from default\n",
      "train acc: 0.4646017551422119\n",
      "train reconstruction error: 518.4947509765625\n",
      "valid acc: 0.4818652868270874\n",
      "valid reconstruction error: 513.9679565429688\n",
      "Evaluating results from default\n",
      "Train\n",
      "Dominant class acc: 0.8157894736842123\n",
      "Model pred acc: 0.5701754385964912\n",
      "Test\n",
      "Dominant class acc: 0.8163265306122455\n",
      "Model pred acc: 0.3673469387755102\n",
      "\n",
      "\n",
      "Training results from chi\n",
      "train acc: 0.4247787594795227\n",
      "train reconstruction error: 3193.3564453125\n",
      "valid acc: 0.5336787700653076\n",
      "valid reconstruction error: 3175.160400390625\n",
      "Evaluating results from chi\n",
      "Train\n",
      "Dominant class acc: 0.8157894736842123\n",
      "Model pred acc: 0.5263157894736842\n",
      "Test\n",
      "Dominant class acc: 0.8163265306122455\n",
      "Model pred acc: 0.5918367346938775\n",
      "\n",
      "\n",
      "Training results from mutual_info\n",
      "train acc: 0.47345131635665894\n",
      "train reconstruction error: 471.717041015625\n",
      "valid acc: 0.6165803074836731\n",
      "valid reconstruction error: 470.0350646972656\n",
      "Evaluating results from mutual_info\n",
      "Train\n",
      "Dominant class acc: 0.8157894736842123\n",
      "Model pred acc: 0.6403508771929824\n",
      "Test\n",
      "Dominant class acc: 0.8163265306122455\n",
      "Model pred acc: 0.6326530612244898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Train Models\n",
    "path = 'data/ctrl_vs_case.csv'\n",
    "modes = ['default', 'chi', 'mutual_info']\n",
    "\n",
    "for mode in modes:\n",
    "    run_pipeline(path, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nonlinear [1024, 512, 256] embed 128\n",
    "print(history.history['classification_accuracy'][-1])\n",
    "print(history.history['reconstruction_mean_absolute_error'][-1])\n",
    "\n",
    "print(history.history['val_classification_accuracy'][-1])\n",
    "print(history.history['val_reconstruction_mean_absolute_error'][-1])\n",
    "\n",
    "\n",
    "# (pred best class 0.8163265306122455)\n",
    "\n",
    "# no class_weights \n",
    "# 0.7920354\n",
    "# 489.65833\n",
    "# 0.8134715\n",
    "# 476.4897\n",
    "\n",
    "# class_weights\n",
    "# 0.53539824\n",
    "# 490.59412\n",
    "# 0.74093264\n",
    "# 476.9029\n",
    "\n",
    "# [256] class_weights\n",
    "# 0.5132743\n",
    "# 514.46576\n",
    "# 0.54404145\n",
    "# 513.9966\n",
    "\n",
    "# [128, 64] class_weights embed 32\n",
    "# 0.53097343\n",
    "# 518.819\n",
    "# 0.7098446\n",
    "# 515.60516\n",
    "\n",
    "# Deeper better than wider!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5176991\n",
      "506.6457\n",
      "0.3834197\n",
      "500.44925\n"
     ]
    }
   ],
   "source": [
    "# Linear [1024, 512, 256] embed 128\n",
    "print(history.history['classification_accuracy'][-1])\n",
    "print(history.history['reconstruction_mean_absolute_error'][-1])\n",
    "\n",
    "print(history.history['val_classification_accuracy'][-1])\n",
    "print(history.history['val_reconstruction_mean_absolute_error'][-1])\n",
    "\n",
    "# no class_weights \n",
    "# 0.8097345\n",
    "# 506.56668\n",
    "# 0.7512953\n",
    "# 497.98688"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 4366)\n"
     ]
    }
   ],
   "source": [
    "transformer = random_projection.GaussianRandomProjection()\n",
    "X_new = transformer.fit_transform(dataset.features.squeeze())\n",
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7794.5112722 ,  25466.99115922,  50625.08150119, ...,\n",
       "        -18741.85192469, -14975.12450545, -24716.42935759],\n",
       "       [ 11071.49525594,  20976.92404719,  39328.86054669, ...,\n",
       "        -14292.56014547,  -6918.82888456, -19860.47128973],\n",
       "       [  8011.61620477,  17182.79149171,  40489.7180404 , ...,\n",
       "        -12251.25835009,  -8394.20052692, -15792.59517772],\n",
       "       ...,\n",
       "       [ 13475.77548306,  21790.79481885,  44833.57616194, ...,\n",
       "        -12127.87087676, -15508.98270711, -16103.80338758],\n",
       "       [  7025.02032196,  16959.86900662,  42436.73625363, ...,\n",
       "        -14074.24514158, -10336.02692565, -16806.70632879],\n",
       "       [ 10728.48657413,  19286.38915573,  44174.01361244, ...,\n",
       "        -17721.62286345, -15242.08650982, -21161.04696759]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://jakevdp.github.io/PythonDataScienceHandbook/05.10-manifold-learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "model = LocallyLinearEmbedding(n_neighbors=30, n_components=3, method='modified',\n",
    "                               eigen_solver='dense')\n",
    "\n",
    "out = model.fit_transform(dataset.features.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(out[:, 0], out[:, 1], out[:, 2])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.features.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "Xtr, Xte, Ytr, Yte = [np.array(data.squeeze()) for data in [dataset.xtr, dataset.xte, dataset.ytr, dataset.yte]]\n",
    "\n",
    "\n",
    "def pca(x, n=10, verbose=False):\n",
    "    model = PCA(n).fit(x)\n",
    "    if verbose:\n",
    "        plt.plot(np.cumsum(model.explained_variance_ratio_))\n",
    "        plt.xlabel('n components')\n",
    "        plt.ylabel('cumulative variance');\n",
    "    return model\n",
    "\n",
    "\n",
    "def results(model, xtr, ytr, xte, yte):\n",
    "    print('train: {}'.format(accuracy_score(ytr, model.predict(xtr))))\n",
    "    print('train pick als: {}'.format(sum(ytr)/len(ytr)))\n",
    "    print('test: {}'.format(accuracy_score(yte, model.predict(xte))))\n",
    "    print('test pick als: {}'.format(sum(yte)/len(yte)))\n",
    "    \n",
    "    \n",
    "\n",
    "def knn(xtr, ytr, xte, yte, n=3):\n",
    "    model = KNeighborsClassifier(n_neighbors=n)\n",
    "    model.fit(xtr, ytr)\n",
    "    \n",
    "    results(model, xtr, ytr, xte, yte)\n",
    "    \n",
    "    \n",
    "def rf(xtr, ytr, xte, yte, n=1):\n",
    "    model = RandomForestClassifier(n_estimators=500, max_depth=2, random_state=0, class_weight='balanced')\n",
    "    model.fit(xtr, ytr)\n",
    "    \n",
    "    results(model, xtr, ytr, xte, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- KNN\n",
      "train: 0.8561643835616438\n",
      "train pick als: 0.815068493150685\n",
      "test: 0.8235294117647058\n",
      "test pick als: 0.8235294117647058\n",
      "- PCA\n",
      "train: 0.8424657534246576\n",
      "train pick als: 0.815068493150685\n",
      "test: 0.8235294117647058\n",
      "test pick als: 0.8235294117647058\n",
      "\n",
      "- RF\n",
      "train: 1.0\n",
      "train pick als: 0.815068493150685\n",
      "test: 0.8235294117647058\n",
      "test pick als: 0.8235294117647058\n",
      "- PCA\n",
      "train: 0.8767123287671232\n",
      "train pick als: 0.815068493150685\n",
      "test: 0.8235294117647058\n",
      "test pick als: 0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "# pca\n",
    "pc = pca(Xtr)\n",
    "xtr = pc.transform(Xtr)\n",
    "xte = pc.transform(Xte)\n",
    "\n",
    "print('- KNN')\n",
    "knn(Xtr, Ytr, Xte, Yte)\n",
    "print('- PCA')\n",
    "knn(xtr, Ytr, xte, Yte)\n",
    "print()\n",
    "print('- RF')\n",
    "rf(Xtr, Ytr, Xte, Yte)\n",
    "print('- PCA')\n",
    "rf(xtr, Ytr, xte, Yte)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
